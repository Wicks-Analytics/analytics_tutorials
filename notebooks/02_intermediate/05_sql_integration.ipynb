{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 05: SQL Database Integration\n",
    "In this tutorial, you'll learn:\n",
    "- How to load data from SQL databases using Polars\n",
    "- Working with SQLite, PostgreSQL, and MySQL\n",
    "- Efficient data loading strategies\n",
    "- Combining SQL queries with analytics_store functions\n",
    "Scenario:\n",
    "Your insurance data is stored in a SQL database. You need to load the data\n",
    "efficiently and perform analytics using analytics_store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from analytics_store import model_validation\n",
    "\n",
    "from utils.database_helpers import create_sqlite_tables, get_sqlite_connection, load_from_sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setting up SQLite database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = project_root / \"data\" / \"insurance.db\"\n",
    "\n",
    "if not db_path.exists():\n",
    "    print(\"Creating database and loading sample data...\")\n",
    "    try:\n",
    "        create_sqlite_tables(str(db_path))\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Error creating database: {e}\")\n",
    "        print(\"Make sure you have run: python utils/data_generators.py\")\n",
    "else:\n",
    "    print(f\"[OK] Database already exists at: {db_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Connecting to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = get_sqlite_connection(str(db_path))\n",
    "print(f\"Connection string: {connection_string}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Loading data from SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple query\n",
    "print(\"\\n3a. Loading all policies...\")\n",
    "policies_df = load_from_sql(\"SELECT * FROM policies\", connection_string)\n",
    "\n",
    "print(f\"[OK] Loaded {len(policies_df)} policies\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(policies_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Using SQL filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load only California policies\n",
    "ca_policies = load_from_sql(\n",
    "    \"\"\"\n",
    "    SELECT * FROM policies\n",
    "    WHERE state = 'CA'\n",
    "    AND customer_age >= 30\n",
    "    \"\"\",\n",
    "    connection_string,\n",
    ")\n",
    "\n",
    "print(f\"[OK] Loaded {len(ca_policies)} California policies (age >= 30)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Loading aggregated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_summary = load_from_sql(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        policy_type,\n",
    "        state,\n",
    "        COUNT(*) as policy_count,\n",
    "        AVG(annual_premium) as avg_premium,\n",
    "        SUM(coverage_amount) as total_coverage\n",
    "    FROM policies\n",
    "    GROUP BY policy_type, state\n",
    "    ORDER BY policy_count DESC\n",
    "    LIMIT 10\n",
    "    \"\"\",\n",
    "    connection_string,\n",
    ")\n",
    "\n",
    "print(\"\\nTop 10 policy type/state combinations:\")\n",
    "print(policy_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Loading data with joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_with_policies = load_from_sql(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        c.claim_id,\n",
    "        c.claim_amount,\n",
    "        c.claim_type,\n",
    "        c.is_fraud,\n",
    "        c.fraud_score,\n",
    "        p.policy_type,\n",
    "        p.customer_age,\n",
    "        p.state,\n",
    "        p.annual_premium\n",
    "    FROM claims c\n",
    "    INNER JOIN policies p ON c.policy_id = p.policy_id\n",
    "    WHERE c.claim_status = 'Approved'\n",
    "    \"\"\",\n",
    "    connection_string,\n",
    ")\n",
    "\n",
    "print(f\"[OK] Loaded {len(claims_with_policies)} approved claims with policy details\")\n",
    "print(\"\\nSample joined data:\")\n",
    "print(claims_with_policies.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Analyzing fraud predictions from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_data = load_from_sql(\"SELECT * FROM fraud_predictions\", connection_string)\n",
    "\n",
    "# Calculate lift curve\n",
    "lift_result = model_validation.calculate_lift_curve(\n",
    "    fraud_data, target_column=\"actual_fraud\", score_column=\"model1_fraud_score\", n_bins=10\n",
    ")\n",
    "\n",
    "print(\"\\nFraud Detection Performance (from SQL data):\")\n",
    "print(f\"- AUC Lift: {lift_result.auc_score_lift:.4f}\")\n",
    "print(f\"- Top decile lift: {lift_result.score_lift_values[0]:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Efficient data loading strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nStrategy 1: Load only needed columns\")\n",
    "limited_cols = load_from_sql(\n",
    "    \"\"\"\n",
    "    SELECT policy_id, customer_age, annual_premium, policy_type\n",
    "    FROM policies\n",
    "    LIMIT 1000\n",
    "    \"\"\",\n",
    "    connection_string,\n",
    ")\n",
    "print(f\"[OK] Loaded {len(limited_cols)} rows with 4 columns\")\n",
    "\n",
    "print(\"\\nStrategy 2: Use WHERE clauses to filter in database\")\n",
    "print(\"(Faster than loading all data and filtering in Python)\")\n",
    "recent_claims = load_from_sql(\n",
    "    \"\"\"\n",
    "    SELECT * FROM claims\n",
    "    WHERE claim_date >= date('now', '-365 days')\n",
    "    \"\"\",\n",
    "    connection_string,\n",
    ")\n",
    "print(f\"[OK] Loaded {len(recent_claims)} recent claims\")\n",
    "\n",
    "print(\"\\nStrategy 3: Use aggregations in SQL when possible\")\n",
    "monthly_stats = load_from_sql(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        strftime('%Y-%m', claim_date) as month,\n",
    "        COUNT(*) as claim_count,\n",
    "        AVG(claim_amount) as avg_amount,\n",
    "        SUM(CASE WHEN is_fraud = 1 THEN 1 ELSE 0 END) as fraud_count\n",
    "    FROM claims\n",
    "    GROUP BY month\n",
    "    ORDER BY month DESC\n",
    "    LIMIT 12\n",
    "    \"\"\",\n",
    "    connection_string,\n",
    ")\n",
    "\n",
    "print(\"\\nMonthly claim statistics:\")\n",
    "print(monthly_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Writing results back to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics and save\n",
    "premium_data = load_from_sql(\"SELECT * FROM premium_predictions LIMIT 1000\", connection_string)\n",
    "\n",
    "metrics = model_validation.calculate_regression_metrics(\n",
    "    premium_data, actual_column=\"actual_premium\", predicted_column=\"model1_predicted_premium\"\n",
    ")\n",
    "\n",
    "# Convert to DataFrame and save\n",
    "metrics_df = metrics.to_polars()\n",
    "metrics_df = metrics_df.with_columns(\n",
    "    [pl.lit(\"model1\").alias(\"model_name\"), pl.lit(pl.datetime(\"now\")).alias(\"calculated_at\")]\n",
    ")\n",
    "\n",
    "# Write to database\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    metrics_df.write_database(\n",
    "        table_name=\"model_metrics\", connection=conn, if_table_exists=\"replace\"\n",
    "    )\n",
    "\n",
    "print(\"[OK] Metrics saved to 'model_metrics' table\")\n",
    "\n",
    "# Verify\n",
    "saved_metrics = load_from_sql(\"SELECT * FROM model_metrics\", connection_string)\n",
    "\n",
    "print(\"\\nSaved metrics:\")\n",
    "print(saved_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Best Practices Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"\"\"\n",
    "[OK] Use SQL WHERE clauses to filter data before loading\n",
    "[OK] Select only the columns you need\n",
    "[OK] Use SQL aggregations when possible (faster than Python)\n",
    "[OK] For large datasets, consider pagination or chunking\n",
    "[OK] Use indexes on frequently queried columns\n",
    "[OK] Close connections when done (handled automatically here)\n",
    "[OK] Use parameterized queries to prevent SQL injection\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Step 11: Exercise\n",
    "print(\"\\n[EXERCISE] EXERCISE: Complex Query Analysis\")\n",
    "print(\"\\nTry this exercise:\")\n",
    "print(\n",
    "    \"\"\"\n",
    "1. Load claims data joined with policies\n",
    "2. Filter for high-value claims (amount > $50,000)\n",
    "3. Calculate fraud detection metrics by policy type\n",
    "4. Save results to a new table\n",
    "\n",
    "Example query:\n",
    "SELECT\n",
    "    p.policy_type,\n",
    "    c.claim_id,\n",
    "    c.claim_amount,\n",
    "    c.is_fraud,\n",
    "    c.fraud_score\n",
    "FROM claims c\n",
    "INNER JOIN policies p ON c.policy_id = p.policy_id\n",
    "WHERE c.claim_amount > 50000\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"\\nKey Takeaways:\")\n",
    "print(\"1. Polars can efficiently load data from SQL databases\")\n",
    "print(\"2. Use SQL for filtering and aggregation when possible\")\n",
    "print(\"3. Join data in SQL before loading for better performance\")\n",
    "print(\"4. analytics_store works seamlessly with SQL-loaded data\")\n",
    "print(\"\\nNext: Tutorial 06 - Population Testing\")\n",
    "\n",
    "# Note about other databases\n",
    "print(\"\\n[INFO] Note: For PostgreSQL or MySQL:\")\n",
    "print(\"   - Update connection string in utils/database_helpers.py\")\n",
    "print(\"   - Install appropriate driver (psycopg2 or pymysql)\")\n",
    "print(\"   - Use get_postgres_connection() or similar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Try the exercise below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}