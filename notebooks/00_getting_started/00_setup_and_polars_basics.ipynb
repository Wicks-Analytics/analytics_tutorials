{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 00: Project Setup and Polars Basics\n",
    "In this tutorial, you'll learn:\n",
    "- How to set up your analytics environment\n",
    "- Basic Polars DataFrame operations\n",
    "- Loading and exploring insurance data\n",
    "- Essential data manipulation techniques\n",
    "- Preparing data for analysis\n",
    "This is a foundational tutorial - complete this before moving to Tutorial 01."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "# Add project root to path to import utilities\n",
    "project_root = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(project_root))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Verifying environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import polars as pl\n",
    "\n",
    "    print(f\"[OK] Polars version: {pl.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"[X] Polars not found. Install with: pip install polars\")\n",
    "\n",
    "try:\n",
    "    from analytics_store import model_validation\n",
    "\n",
    "    print(\"[OK] analytics_store package found\")\n",
    "except ImportError:\n",
    "    print(\"[X] analytics_store not found. Install with:\")\n",
    "    print(\"  pip install git+https://github.com/Wicks-Analytics/analytics_store\")\n",
    "\n",
    "# Check if data exists\n",
    "data_dir = project_root / \"data\"\n",
    "if not data_dir.exists():\n",
    "    print(f\"[X] Data directory not found: {data_dir}\")\n",
    "    print(\"  Run: python setup_database.py\")\n",
    "\n",
    "print(f\"[OK] Data directory found: {data_dir}\")\n",
    "print(\"\\n[SUCCESS] Environment setup verified!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Loading data with Polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load insurance policies data\n",
    "policies_path = data_dir / \"insurance_policies.csv\"\n",
    "\n",
    "if not policies_path.exists():\n",
    "    print(f\"[X] Data file not found: {policies_path}\")\n",
    "    print(\"  Run: python setup_database.py\")\n",
    "\n",
    "# Load with Polars - note how fast this is!\n",
    "df = pl.read_csv(policies_path)\n",
    "\n",
    "print(f\"[OK] Loaded {len(df)} insurance policies\")\n",
    "print(f\"[OK] Columns: {df.shape[1]}\")\n",
    "print(f\"[OK] Memory usage: {df.estimated_size('mb'):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Exploring the data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nColumn names and types:\")\n",
    "for col, dtype in zip(df.columns, df.dtypes):\n",
    "    print(f\"  - {col:20s} : {dtype}\")\n",
    "\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Selecting and filtering columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select specific columns\n",
    "customer_info = df.select([\"policy_id\", \"age\", \"gender\", \"region\"])\n",
    "print(\"\\nSelected customer info columns:\")\n",
    "print(customer_info.head())\n",
    "\n",
    "# Select by data type\n",
    "numeric_cols = df.select(pl.col(pl.NUMERIC_DTYPES))\n",
    "print(f\"\\nNumeric columns: {numeric_cols.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Filtering rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by condition\n",
    "young_drivers = df.filter(pl.col(\"age\") < 30)\n",
    "print(f\"\\nPolicies for drivers under 30: {len(young_drivers)}\")\n",
    "\n",
    "# Multiple conditions\n",
    "high_value_young = df.filter((pl.col(\"age\") < 30) & (pl.col(\"annual_premium\") > 1000))\n",
    "print(f\"Young drivers with premium > $1000: {len(high_value_young)}\")\n",
    "\n",
    "# Filter by string matching\n",
    "urban_policies = df.filter(pl.col(\"region\").str.contains(\"Urban\"))\n",
    "print(f\"Urban region policies: {len(urban_policies)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Adding and modifying columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column\n",
    "df_with_monthly = df.with_columns([(pl.col(\"annual_premium\") / 12).alias(\"monthly_premium\")])\n",
    "\n",
    "print(\"\\nAdded monthly_premium column:\")\n",
    "print(df_with_monthly.select([\"policy_id\", \"annual_premium\", \"monthly_premium\"]).head())\n",
    "\n",
    "# Create age groups\n",
    "df_with_groups = df.with_columns(\n",
    "    [\n",
    "        pl.when(pl.col(\"age\") < 25)\n",
    "        .then(pl.lit(\"Young\"))\n",
    "        .when(pl.col(\"age\") < 40)\n",
    "        .then(pl.lit(\"Middle\"))\n",
    "        .otherwise(pl.lit(\"Senior\"))\n",
    "        .alias(\"age_group\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\nAge group distribution:\")\n",
    "print(df_with_groups.group_by(\"age_group\").agg(pl.count()).sort(\"age_group\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Aggregations and grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by region\n",
    "region_stats = (\n",
    "    df.group_by(\"region\")\n",
    "    .agg(\n",
    "        [\n",
    "            pl.count().alias(\"policy_count\"),\n",
    "            pl.col(\"annual_premium\").mean().alias(\"avg_premium\"),\n",
    "            pl.col(\"annual_premium\").median().alias(\"median_premium\"),\n",
    "            pl.col(\"annual_premium\").std().alias(\"std_premium\"),\n",
    "        ]\n",
    "    )\n",
    "    .sort(\"avg_premium\", descending=True)\n",
    ")\n",
    "\n",
    "print(\"\\nPremium statistics by region:\")\n",
    "print(region_stats)\n",
    "\n",
    "# Multiple grouping columns\n",
    "gender_region_stats = (\n",
    "    df.group_by([\"gender\", \"region\"])\n",
    "    .agg([pl.count().alias(\"count\"), pl.col(\"annual_premium\").mean().alias(\"avg_premium\")])\n",
    "    .sort([\"gender\", \"avg_premium\"], descending=[False, True])\n",
    ")\n",
    "\n",
    "print(\"\\nPremium by gender and region:\")\n",
    "print(gender_region_stats.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Sorting and ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by premium\n",
    "top_premiums = (\n",
    "    df.select([\"policy_id\", \"age\", \"vehicle_type\", \"annual_premium\"])\n",
    "    .sort(\"annual_premium\", descending=True)\n",
    "    .head(10)\n",
    ")\n",
    "\n",
    "print(\"\\nTop 10 highest premiums:\")\n",
    "print(top_premiums)\n",
    "\n",
    "# Add rank\n",
    "df_with_rank = df.with_columns(\n",
    "    [pl.col(\"annual_premium\").rank(descending=True).alias(\"premium_rank\")]\n",
    ")\n",
    "\n",
    "print(\"\\nPolicies with premium rank:\")\n",
    "print(df_with_rank.select([\"policy_id\", \"annual_premium\", \"premium_rank\"]).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Handling missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values\n",
    "null_counts = df.null_count()\n",
    "print(\"\\nNull values per column:\")\n",
    "print(null_counts)\n",
    "\n",
    "# Fill null values (example)\n",
    "df_filled = df.with_columns([pl.col(\"annual_premium\").fill_null(pl.col(\"annual_premium\").median())])\n",
    "print(\"[OK] Filled null values with median\")\n",
    "\n",
    "# Drop rows with any nulls\n",
    "df_clean = df.drop_nulls()\n",
    "print(f\"[OK] Rows after dropping nulls: {len(df_clean)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Joining datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load claims data\n",
    "claims_path = data_dir / \"insurance_claims.csv\"\n",
    "\n",
    "if claims_path.exists():\n",
    "    claims_df = pl.read_csv(claims_path)\n",
    "    print(f\"[OK] Loaded {len(claims_df)} claims\")\n",
    "\n",
    "    # Join policies with claims\n",
    "    joined = df.join(claims_df, on=\"policy_id\", how=\"left\")\n",
    "    print(f\"[OK] Joined data shape: {joined.shape}\")\n",
    "\n",
    "    # Count claims per policy\n",
    "    claims_per_policy = joined.group_by(\"policy_id\").agg([pl.count().alias(\"claim_count\")])\n",
    "\n",
    "    print(\"\\nClaims per policy distribution:\")\n",
    "    print(claims_per_policy.group_by(\"claim_count\").agg(pl.count()).sort(\"claim_count\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Advanced expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple transformations in one go\n",
    "df_transformed = df.with_columns(\n",
    "    [\n",
    "        # Normalize premium (z-score)\n",
    "        (\n",
    "            (pl.col(\"annual_premium\") - pl.col(\"annual_premium\").mean())\n",
    "            / pl.col(\"annual_premium\").std()\n",
    "        ).alias(\"premium_zscore\"),\n",
    "        # Premium percentile\n",
    "        (pl.col(\"annual_premium\").rank() / pl.count() * 100).alias(\"premium_percentile\"),\n",
    "        # Risk category based on age and vehicle\n",
    "        pl.when((pl.col(\"age\") < 25) & (pl.col(\"vehicle_type\") == \"Sports\"))\n",
    "        .then(pl.lit(\"High Risk\"))\n",
    "        .when(pl.col(\"age\") > 60)\n",
    "        .then(pl.lit(\"Senior\"))\n",
    "        .otherwise(pl.lit(\"Standard\"))\n",
    "        .alias(\"risk_category\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\nTransformed data sample:\")\n",
    "print(\n",
    "    df_transformed.select(\n",
    "        [\n",
    "            \"policy_id\",\n",
    "            \"age\",\n",
    "            \"vehicle_type\",\n",
    "            \"annual_premium\",\n",
    "            \"premium_zscore\",\n",
    "            \"premium_percentile\",\n",
    "            \"risk_category\",\n",
    "        ]\n",
    "    ).head()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create outputs directory\n",
    "output_dir = project_root / \"outputs\"\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save to CSV\n",
    "output_path = output_dir / \"00_polars_practice.csv\"\n",
    "df_transformed.write_csv(output_path)\n",
    "print(f\"[OK] Saved results to: {output_path}\")\n",
    "\n",
    "# Save to Parquet (more efficient)\n",
    "parquet_path = output_dir / \"00_polars_practice.parquet\"\n",
    "df_transformed.write_parquet(parquet_path)\n",
    "print(f\"[OK] Saved to Parquet: {parquet_path}\")\n",
    "\n",
    "# Compare file sizes\n",
    "csv_size = output_path.stat().st_size / 1024 / 1024\n",
    "parquet_size = parquet_path.stat().st_size / 1024 / 1024\n",
    "\n",
    "print(\"\\nFile size comparison:\")\n",
    "print(f\"  CSV:     {csv_size:.2f} MB\")\n",
    "print(f\"  Parquet: {parquet_size:.2f} MB\")\n",
    "print(f\"  Savings: {(1 - parquet_size / csv_size) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13: Polars performance tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nKey performance advantages of Polars:\")\n",
    "print(\"1. [OK] Lazy evaluation - operations are optimized before execution\")\n",
    "print(\"2. [OK] Parallel processing - uses all CPU cores automatically\")\n",
    "print(\"3. [OK] Memory efficient - processes data in chunks\")\n",
    "print(\"4. [OK] Fast I/O - optimized CSV and Parquet readers\")\n",
    "print(\"5. [OK] Expression API - vectorized operations\")\n",
    "\n",
    "# Demonstrate lazy evaluation\n",
    "print(\"\\nLazy evaluation example:\")\n",
    "lazy_query = (\n",
    "    pl.scan_csv(policies_path)  # Lazy read\n",
    "    .filter(pl.col(\"age\") > 30)\n",
    "    .group_by(\"region\")\n",
    "    .agg(pl.col(\"annual_premium\").mean())\n",
    "    .sort(\"annual_premium\", descending=True)\n",
    ")\n",
    "\n",
    "print(\"[OK] Query built (not executed yet)\")\n",
    "\n",
    "# Execute the query\n",
    "result = lazy_query.collect()\n",
    "print(\"[OK] Query executed\")\n",
    "print(result)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"\\n[EXERCISE] Key Takeaways:\")\n",
    "print(\"1. Polars is fast and memory-efficient for data analysis\")\n",
    "print(\"2. Use .select() for columns, .filter() for rows\")\n",
    "print(\"3. .with_columns() adds/modifies columns efficiently\")\n",
    "print(\"4. .group_by() + .agg() for aggregations\")\n",
    "print(\"5. Expressions (pl.col()) are powerful and composable\")\n",
    "print(\"6. Lazy evaluation optimizes complex queries\")\n",
    "print(\"7. Parquet format is more efficient than CSV\")\n",
    "\n",
    "print(\"\\n Practice Exercises:\")\n",
    "print(\"1. Find the average premium for each vehicle type\")\n",
    "print(\"2. Create a 'high_value' flag for premiums > $1500\")\n",
    "print(\"3. Calculate the age distribution by region\")\n",
    "print(\"4. Join policies with claims and find policies with no claims\")\n",
    "print(\"5. Create a risk score based on age, vehicle type, and region\")\n",
    "\n",
    "print(\"\\n Polars Resources:\")\n",
    "print(\"- Documentation: https://pola-rs.github.io/polars/\")\n",
    "print(\"- User Guide: https://pola-rs.github.io/polars-book/\")\n",
    "print(\"- GitHub: https://github.com/pola-rs/polars\")\n",
    "\n",
    "print(\"\\n->  Next: Tutorial 01 - Lift Analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Try the exercise below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}