{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 00: Project Setup and Polars Basics",
    "In this tutorial, you'll learn:",
    "- How to set up your analytics environment",
    "- Basic Polars DataFrame operations",
    "- Loading and exploring insurance data",
    "- Essential data manipulation techniques",
    "- Preparing data for analysis",
    "This is a foundational tutorial - complete this before moving to Tutorial 01."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl",
    "import sys",
    "from pathlib import Path",
    "",
    "# Add project root to path to import utilities",
    "project_root = Path.cwd().parent.parent",
    "sys.path.insert(0, str(project_root))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Verifying environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:",
    "    import polars as pl",
    "    print(f\"\u2713 Polars version: {pl.__version__}\")",
    "except ImportError:",
    "    print(\"\u2717 Polars not found. Install with: pip install polars\")",
    "try:",
    "    from analytics_store import model_validation",
    "    print(\"\u2713 analytics_store package found\")",
    "except ImportError:",
    "    print(\"\u2717 analytics_store not found. Install with:\")",
    "    print(\"  pip install git+https://github.com/Wicks-Analytics/analytics_store\")",
    "# Check if data exists",
    "data_dir = project_root / 'data'",
    "if not data_dir.exists():",
    "    print(f\"\u2717 Data directory not found: {data_dir}\")",
    "    print(\"  Run: python setup_database.py\")",
    "print(f\"\u2713 Data directory found: {data_dir}\")",
    "print(\"\\n\u2705 Environment setup verified!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Loading data with Polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load insurance policies data",
    "policies_path = data_dir / 'insurance_policies.csv'",
    "if not policies_path.exists():",
    "    print(f\"\u2717 Data file not found: {policies_path}\")",
    "    print(\"  Run: python setup_database.py\")",
    "# Load with Polars - note how fast this is!",
    "df = pl.read_csv(policies_path)",
    "print(f\"\u2713 Loaded {len(df)} insurance policies\")",
    "print(f\"\u2713 Columns: {df.shape[1]}\")",
    "print(f\"\u2713 Memory usage: {df.estimated_size('mb'):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Exploring the data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nColumn names and types:\")",
    "for col, dtype in zip(df.columns, df.dtypes):",
    "    print(f\"  - {col:20s} : {dtype}\")",
    "print(\"\\nFirst 5 rows:\")",
    "display(df.head())",
    "print(\"\\nBasic statistics:\")",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Selecting and filtering columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select specific columns",
    "customer_info = df.select(['policy_id', 'age', 'gender', 'region'])",
    "print(\"\\nSelected customer info columns:\")",
    "print(customer_info.head())",
    "# Select by data type",
    "numeric_cols = df.select(pl.col(pl.NUMERIC_DTYPES))",
    "print(f\"\\nNumeric columns: {numeric_cols.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Filtering rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by condition",
    "young_drivers = df.filter(pl.col('age') < 30)",
    "print(f\"\\nPolicies for drivers under 30: {len(young_drivers)}\")",
    "# Multiple conditions",
    "high_value_young = df.filter(",
    "    (pl.col('age') < 30) &",
    "    (pl.col('annual_premium') > 1000)",
    ")",
    "print(f\"Young drivers with premium > $1000: {len(high_value_young)}\")",
    "# Filter by string matching",
    "urban_policies = df.filter(pl.col('region').str.contains('Urban'))",
    "print(f\"Urban region policies: {len(urban_policies)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Adding and modifying columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column",
    "df_with_monthly = df.with_columns([",
    "    (pl.col('annual_premium') / 12).alias('monthly_premium')",
    "])",
    "print(\"\\nAdded monthly_premium column:\")",
    "print(df_with_monthly.select(['policy_id', 'annual_premium', 'monthly_premium']).head())",
    "# Create age groups",
    "df_with_groups = df.with_columns([",
    "    pl.when(pl.col('age') < 25)",
    "      .then(pl.lit('Young'))",
    "      .when(pl.col('age') < 40)",
    "      .then(pl.lit('Middle'))",
    "      .otherwise(pl.lit('Senior'))",
    "      .alias('age_group')",
    "])",
    "print(\"\\nAge group distribution:\")",
    "print(df_with_groups.group_by('age_group').agg(pl.count()).sort('age_group'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Aggregations and grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by region",
    "region_stats = df.group_by('region').agg([",
    "    pl.count().alias('policy_count'),",
    "    pl.col('annual_premium').mean().alias('avg_premium'),",
    "    pl.col('annual_premium').median().alias('median_premium'),",
    "    pl.col('annual_premium').std().alias('std_premium')",
    "]).sort('avg_premium', descending=True)",
    "print(\"\\nPremium statistics by region:\")",
    "print(region_stats)",
    "# Multiple grouping columns",
    "gender_region_stats = df.group_by(['gender', 'region']).agg([",
    "    pl.count().alias('count'),",
    "    pl.col('annual_premium').mean().alias('avg_premium')",
    "]).sort(['gender', 'avg_premium'], descending=[False, True])",
    "print(\"\\nPremium by gender and region:\")",
    "print(gender_region_stats.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Sorting and ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by premium",
    "top_premiums = df.select([",
    "    'policy_id', 'age', 'vehicle_type', 'annual_premium'",
    "]).sort('annual_premium', descending=True).head(10)",
    "print(\"\\nTop 10 highest premiums:\")",
    "print(top_premiums)",
    "# Add rank",
    "df_with_rank = df.with_columns([",
    "    pl.col('annual_premium').rank(descending=True).alias('premium_rank')",
    "])",
    "print(\"\\nPolicies with premium rank:\")",
    "print(df_with_rank.select(['policy_id', 'annual_premium', 'premium_rank']).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Handling missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values",
    "null_counts = df.null_count()",
    "print(\"\\nNull values per column:\")",
    "print(null_counts)",
    "# Fill null values (example)",
    "df_filled = df.with_columns([",
    "    pl.col('annual_premium').fill_null(pl.col('annual_premium').median())",
    "])",
    "print(\"\u2713 Filled null values with median\")",
    "# Drop rows with any nulls",
    "df_clean = df.drop_nulls()",
    "print(f\"\u2713 Rows after dropping nulls: {len(df_clean)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Joining datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load claims data",
    "claims_path = data_dir / 'insurance_claims.csv'",
    "if claims_path.exists():",
    "    claims_df = pl.read_csv(claims_path)",
    "    print(f\"\u2713 Loaded {len(claims_df)} claims\")",
    "    # Join policies with claims",
    "    joined = df.join(",
    "        claims_df,",
    "        on='policy_id',",
    "        how='left'",
    "    )",
    "    print(f\"\u2713 Joined data shape: {joined.shape}\")",
    "    # Count claims per policy",
    "    claims_per_policy = joined.group_by('policy_id').agg([",
    "        pl.count().alias('claim_count')",
    "    ])",
    "    print(\"\\nClaims per policy distribution:\")",
    "    print(claims_per_policy.group_by('claim_count').agg(pl.count()).sort('claim_count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Advanced expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple transformations in one go",
    "df_transformed = df.with_columns([",
    "    # Normalize premium (z-score)",
    "    ((pl.col('annual_premium') - pl.col('annual_premium').mean()) /",
    "     pl.col('annual_premium').std()).alias('premium_zscore'),",
    "    # Premium percentile",
    "    (pl.col('annual_premium').rank() / pl.count() * 100).alias('premium_percentile'),",
    "    # Risk category based on age and vehicle",
    "    pl.when((pl.col('age') < 25) & (pl.col('vehicle_type') == 'Sports'))",
    "      .then(pl.lit('High Risk'))",
    "      .when(pl.col('age') > 60)",
    "      .then(pl.lit('Senior'))",
    "      .otherwise(pl.lit('Standard'))",
    "      .alias('risk_category')",
    "])",
    "print(\"\\nTransformed data sample:\")",
    "print(df_transformed.select([",
    "    'policy_id', 'age', 'vehicle_type', 'annual_premium',",
    "    'premium_zscore', 'premium_percentile', 'risk_category'",
    "]).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create outputs directory",
    "output_dir = project_root / 'outputs'",
    "output_dir.mkdir(exist_ok=True)",
    "# Save to CSV",
    "output_path = output_dir / '00_polars_practice.csv'",
    "df_transformed.write_csv(output_path)",
    "print(f\"\u2713 Saved results to: {output_path}\")",
    "# Save to Parquet (more efficient)",
    "parquet_path = output_dir / '00_polars_practice.parquet'",
    "df_transformed.write_parquet(parquet_path)",
    "print(f\"\u2713 Saved to Parquet: {parquet_path}\")",
    "# Compare file sizes",
    "csv_size = output_path.stat().st_size / 1024 / 1024",
    "parquet_size = parquet_path.stat().st_size / 1024 / 1024",
    "print(f\"\\nFile size comparison:\")",
    "print(f\"  CSV:     {csv_size:.2f} MB\")",
    "print(f\"  Parquet: {parquet_size:.2f} MB\")",
    "print(f\"  Savings: {(1 - parquet_size/csv_size)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13: Polars performance tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nKey performance advantages of Polars:\")",
    "print(\"1. \u2713 Lazy evaluation - operations are optimized before execution\")",
    "print(\"2. \u2713 Parallel processing - uses all CPU cores automatically\")",
    "print(\"3. \u2713 Memory efficient - processes data in chunks\")",
    "print(\"4. \u2713 Fast I/O - optimized CSV and Parquet readers\")",
    "print(\"5. \u2713 Expression API - vectorized operations\")",
    "# Demonstrate lazy evaluation",
    "print(\"\\nLazy evaluation example:\")",
    "lazy_query = (",
    "    pl.scan_csv(policies_path)  # Lazy read",
    "    .filter(pl.col('age') > 30)",
    "    .group_by('region')",
    "    .agg(pl.col('annual_premium').mean())",
    "    .sort('annual_premium', descending=True)",
    ")",
    "print(\"\u2713 Query built (not executed yet)\")",
    "# Execute the query",
    "result = lazy_query.collect()",
    "print(\"\u2713 Query executed\")",
    "print(result)",
    "print(\"\\n\" + \"=\" * 70)",
    "print(\"\\n\ud83c\udf93 Key Takeaways:\")",
    "print(\"1. Polars is fast and memory-efficient for data analysis\")",
    "print(\"2. Use .select() for columns, .filter() for rows\")",
    "print(\"3. .with_columns() adds/modifies columns efficiently\")",
    "print(\"4. .group_by() + .agg() for aggregations\")",
    "print(\"5. Expressions (pl.col()) are powerful and composable\")",
    "print(\"6. Lazy evaluation optimizes complex queries\")",
    "print(\"7. Parquet format is more efficient than CSV\")",
    "print(\"\\n\ud83c\udfaf Practice Exercises:\")",
    "print(\"1. Find the average premium for each vehicle type\")",
    "print(\"2. Create a 'high_value' flag for premiums > $1500\")",
    "print(\"3. Calculate the age distribution by region\")",
    "print(\"4. Join policies with claims and find policies with no claims\")",
    "print(\"5. Create a risk score based on age, vehicle type, and region\")",
    "print(\"\\n\ud83d\udcda Polars Resources:\")",
    "print(\"- Documentation: https://pola-rs.github.io/polars/\")",
    "print(\"- User Guide: https://pola-rs.github.io/polars-book/\")",
    "print(\"- GitHub: https://github.com/pola-rs/polars\")",
    "print(\"\\n\u27a1\ufe0f  Next: Tutorial 01 - Lift Analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Try the exercise below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here",
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}