{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 01: Introduction to Lift Analysis\n",
    "In this tutorial, you'll learn:\n",
    "- What lift curves are and why they're important\n",
    "- How to calculate lift metrics using analytics_store\n",
    "- How to interpret lift results for insurance claim predictions\n",
    "- How to visualize lift curves\n",
    "Scenario:\n",
    "You have a model that predicts which insurance claims are likely to be fraudulent.\n",
    "You want to understand how well the model identifies fraud across different score ranges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "# Add project root to path to import utilities\n",
    "project_root = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from analytics_store import model_validation, validation_plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Loading fraud prediction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = project_root / \"data\" / \"fraud_predictions.csv\"\n",
    "\n",
    "if not data_path.exists():\n",
    "    print(f\"[ERROR] Data file not found: {data_path}\")\n",
    "    print(\"Please run: python utils/data_generators.py\")\n",
    "\n",
    "df = pl.read_csv(data_path)\n",
    "print(f\"[OK] Loaded {len(df)} predictions\")\n",
    "print(\"\\nData preview:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Understanding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_rate = df[\"actual_fraud\"].mean()\n",
    "print(f\"Overall fraud rate: {fraud_rate:.2%}\")\n",
    "print(f\"Total frauds: {df['actual_fraud'].sum()}\")\n",
    "print(f\"Total non-frauds: {(1 - df['actual_fraud']).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Calculating lift curve for Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lift_result = model_validation.calculate_lift_curve(\n",
    "    df,\n",
    "    target_column=\"actual_fraud\",\n",
    "    score_column=\"model1_fraud_score\",\n",
    "    n_bins=10,  # Divide data into 10 deciles\n",
    ")\n",
    "\n",
    "print(\"\\nLift Metrics:\")\n",
    "print(f\"- Baseline (overall fraud rate): {lift_result.baseline:.4f}\")\n",
    "print(f\"- AUC Lift Score: {lift_result.auc_score_lift:.4f}\")\n",
    "print(f\"- Number of bins: {len(lift_result.score_lift_values)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Examining lift by decile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDecile | Fraud Rate | Lift | Cumulative Lift\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for i, (rate, lift, cum_lift) in enumerate(\n",
    "    zip(\n",
    "        lift_result.score_target_rates,\n",
    "        lift_result.score_lift_values,\n",
    "        lift_result.score_cumulative_lift,\n",
    "    ),\n",
    "    1,\n",
    "):\n",
    "    print(f\"  {i:2d}   |   {rate:.4f}   | {lift:.2f} |      {cum_lift:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Interpreting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_decile_lift = lift_result.score_lift_values[0]\n",
    "top_decile_rate = lift_result.score_target_rates[0]\n",
    "\n",
    "print(\"\\nTop decile (highest scores):\")\n",
    "print(f\"- Fraud rate: {top_decile_rate:.2%}\")\n",
    "print(f\"- Lift: {top_decile_lift:.2f}x\")\n",
    "print(\"- Interpretation: The top 10% of claims by score contain\")\n",
    "print(f\"  {top_decile_lift:.1f}x more fraud than random selection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Converting results to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lift_df = lift_result.to_polars()\n",
    "print(\"\\nLift curve data:\")\n",
    "display(lift_df)\n",
    "\n",
    "# Optional: Save results\n",
    "output_dir = project_root / \"outputs\"\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "lift_df.write_csv(output_dir / \"01_lift_results.csv\")\n",
    "print(f\"\\n[OK] Results saved to: {output_dir / '01_lift_results.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Creating lift curve visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    validation_plots.plot_lift_curve(\n",
    "        df,\n",
    "        target_column=\"actual_fraud\",\n",
    "        score_column=\"model1_fraud_score\",\n",
    "        n_bins=10,\n",
    "        title=\"Fraud Detection Model - Lift Curve\",\n",
    "    )\n",
    "    print(\"[OK] Lift curve plot displayed\")\n",
    "    print(\"(Close the plot window to continue)\")\n",
    "except Exception as e:\n",
    "    print(f\"[WARNING] Could not create plot: {e}\")\n",
    "\n",
    "# Step 8: Exercise - Compare with Model 2\n",
    "print(\"\\n[EXERCISE] EXERCISE: Try calculating lift for Model 2\")\n",
    "print(\"Hint: Use 'model2_fraud_score' as the score_column\")\n",
    "print(\"\\nUncomment the code below to see the solution:\")\n",
    "print(\n",
    "    \"\"\"\n",
    "# lift_result_m2 = model_validation.calculate_lift_curve(\n",
    "#     df,\n",
    "#     target_column='actual_fraud',\n",
    "#     score_column='model2_fraud_score',\n",
    "#     n_bins=10\n",
    "# )\n",
    "# print(f\"Model 2 AUC Lift: {lift_result_m2.auc_score_lift:.4f}\")\n",
    "# print(f\"Model 1 AUC Lift: {lift_result.auc_score_lift:.4f}\")\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"\\nKey Takeaways:\")\n",
    "print(\"1. Lift curves show how well a model ranks predictions\")\n",
    "print(\"2. Higher lift in top deciles = better model performance\")\n",
    "print(\"3. AUC Lift summarizes overall ranking performance\")\n",
    "print(\"4. Lift > 1 means better than random selection\")\n",
    "print(\"\\nNext: Tutorial 02 - ROC Curve Analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Try the exercise below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}